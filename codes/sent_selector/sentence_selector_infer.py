import json
from pathlib import Path
from transformers import AutoTokenizer
import torch
from transformers import EncoderDecoderModel
from torch.utils.data import DataLoader
from transformers import AdamW
import numpy as np
from hanziconv import HanziConv
import argparse
import time
from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments


## Retrieve load the dataset from the corresponding files
def get_dataset(sentlabelfile, contentfile):
    with open(sentlabelfile, "r", encoding="utf-8") as fd:
        sentlabels = [line.rstrip() for line in fd.readlines()]
        allsentbounds, allsentlabels = [], []
        for sentlabel in sentlabels:
            sentlabelsplitted = sentlabel.split(";")
            sentbounds = []
            sentlabels = []
            for info in sentlabelsplitted:
                bdl, bdh, label = info.split(",")
                sentbounds.append([int(bdl), int(bdh)])
                sentlabels.append(float(label))
            allsentbounds.append(sentbounds)
            allsentlabels.append(sentlabels)

    with open(contentfile, "r", encoding="utf-8") as fd:
        contents = [line.rstrip() for line in fd.readlines()]

    assert len(allsentlabels) == len(contents) and len(allsentlabels) == len(contents), \
        "Data Fields (Files) have different lengths"

    return allsentbounds, allsentlabels, contents


def show_answer(tokenizer_model, in_encodings, sentbound, sentlabel, idx):
    print("Index :: ", idx)
    print("Input (Content) :: ", tokenizer_model.decode(in_encodings['input_ids'][idx]))
    bod = in_encodings['input_ids'][idx].index(tokenizer.cls_token_id)
    eod = in_encodings['input_ids'][idx].index(tokenizer.sep_token_id)
    trimmed_text = in_encodings['input_ids'][idx][bod+1:eod]
    for bound, label in zip(sentbound[idx], sentlabel[idx]):
        print("Label (Do Select) :: ", label)
        print("Sentence :: ", tokenizer_model.decode(trimmed_text[bound[0]:bound[1]]))
    print("=======================================")


class GenerationDataset(torch.utils.data.Dataset):  # torch dataset object
    def __init__(self, input_encodings, sentbounds, sentlabels):  # takes in encoded datasets generated by huggingface tokenizers
        self.input_encodings = input_encodings

    def __getitem__(self, idx):  # for each idx, pass the input encodings and output encodings
        input_encodings_dict = {key: torch.tensor(val[idx]) for key, val in self.input_encodings.items()}
        input_encodings_dict["index"] = idx
        return input_encodings_dict

    def __len__(self):  # get the length (number of samples) in the dataset
        return len(self.input_encodings.input_ids)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Training Arguments")
    parser.add_argument("--contentfile", type=str, required=True,
                        help="Content (Article) File")
    parser.add_argument("--sentlabelfile", type=str, required=True,
                        help="Sentence Label File (Dummy Label is Fine, But Must Present Triplet for each Sentence)")

    parser.add_argument("--batch_size", type=int, default=16, help="Default: 16")
    parser.add_argument("--modelencdec_ckpt", type=str, default="", help="The EncoderDecoderModel")
    parser.add_argument("--modelsentscore_ckpt", type=str, default="", help="The Sentence Scoring Model")
    parser.add_argument("--outfile", type=str, required=True, help="Output File")
    parser.add_argument("--do_assess", action="store_true", default=False, help="Whether to Assess Prediction")
    args = parser.parse_args()
    print("Get all Arguments:")
    for arg in vars(args):
        print("{}: {}".format(arg, getattr(args, arg)))

    modelbase = "bert-base-chinese"

    # sentlabel must be provided, even if as a dummy label
    test_sentbounds, test_sentlabels, test_contents = get_dataset(args.sentlabelfile, args.contentfile)

    tokenizer = AutoTokenizer.from_pretrained(modelbase)
    tokenizer.add_special_tokens({"additional_special_tokens": ["[unused1]"]})
    test_input_encodings = tokenizer(test_contents, truncation=True, padding=True)

    print("Show some examples: ")
    show_answer(tokenizer, test_input_encodings, test_sentbounds, test_sentlabels, 0)
    show_answer(tokenizer, test_input_encodings, test_sentbounds, test_sentlabels, -1)
    print("Length of Train Set: {}".format(len(test_contents)))
    print("Done Dataset Processing")

    """The dataset is now ready for training"""
    test_dataset = GenerationDataset(test_input_encodings, test_sentbounds, test_sentlabels)
    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)

    print("Load from modelckpt: {}".format(args.modelencdec_ckpt))
    model_encdec = EncoderDecoderModel.from_pretrained(args.modelencdec_ckpt)

    # Create sentence scoring model
    for param in model_encdec.parameters(): # freeze everything
        param.requires_grad = False
    model_encoder = model_encdec.encoder
    model_sent_score = torch.nn.Sequential(torch.nn.Linear(768 * 2, 2),
                                           torch.nn.LogSoftmax(dim=1)) # Pooler output + Sentence encoding via Mean-over-Position
    model_sent_score.load_state_dict(torch.load(args.modelsentscore_ckpt))
    device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
    model_encoder.to(device)
    model_encoder.eval()
    model_sent_score.to(device)
    model_sent_score.eval()
    print("Model Configuration")
    print(model_encoder.config)
    print("Model Architecture")
    print(model_encoder)

    loss_funct = torch.nn.NLLLoss()

    step = 0
    start = time.time()
    all_predscores = []
    fd = open(args.outfile, "w", encoding="utf-8")
    for step, batch_in in enumerate(test_loader):
        input_ids = batch_in["input_ids"].to(device)
        attention_mask = batch_in["attention_mask"].to(device)
        outputs = model_encoder(input_ids=input_ids, attention_mask=attention_mask)
        assert len(outputs["last_hidden_state"]) == len(batch_in["index"]), \
            "For the current batch, the information of concern are not of the same size." # chaining the length comparison
        for _lhs, idx, _intok in zip(outputs["last_hidden_state"], batch_in["index"], batch_in["input_ids"]):
            intok = _intok[1:]
            lhs = _lhs[1:] # remove CLS
            bounds = test_sentbounds[idx]
            labels = test_sentlabels[idx]
            content_emb = lhs[:bounds[-1][1]].mean(dim=0)
            in_batch_sample = []
            out_batch_sample = []
            for bound, label in zip(bounds, labels):
                sent_embed = lhs[bound[0]:bound[1]].mean(axis=0)
                in_batch_sample.append(torch.cat([content_emb, sent_embed]).unsqueeze(0))
                out_batch_sample.append(label)
                # print(tokenizer.decode(intok[bound[0]:bound[1]]), flush=True)
            in_batch_sample = torch.cat(in_batch_sample, dim=0).to(device)
            out_batch_sample = torch.LongTensor(out_batch_sample).to(device)
            pred_scores = model_sent_score(in_batch_sample)
            loss = loss_funct(pred_scores, out_batch_sample)
            # print("Sample - {}, Loss: {}, Acc: {}".format(idx, loss, (pred_scores.argmax(dim=1) == out_batch_sample).float().mean()), flush=True)
            all_predscores.append(pred_scores.detach().cpu().numpy())
            content_reduced_list = []
            for bound, pred_score in zip(bounds, pred_scores):
                if pred_score.argmax() == 1: # hard code selection threshold for now
                    content_reduced_list.append(tokenizer.decode(intok[bound[0]:bound[1]]))
            content_reduced = " [unused1] ".join(content_reduced_list) + "\n"
            # print(content_reduced, flush=True)
            fd.write(content_reduced)

        if ((step + 1) % 200) == 0:
            end = time.time()
            print(
                "Step: {}, Duration (From Last Print-Out): {}".format(step + 1, end - start))
            start = time.time()
    fd.close()
    end = time.time()

    if args.do_assess:
        acc_by_sents = []
        acc_by_contents = []
        for preds, grds in zip(all_predscores, test_sentlabels):
            preds = np.array(preds).argmax(axis=1)
            grds = np.array(grds)
            acc_raw = (preds == grds).astype("int").tolist()
            acc_by_sents.extend(acc_raw)
            acc_by_contents.append(np.mean(acc_raw))

        print("Final Accuracies:\n By Sentences {},\n By Contents {}".format(np.mean(acc_by_sents), np.mean(acc_by_contents)))
        print("Test Set Ratio of Selected Sentences:\n By Sentences {},\n By Contents {}".format(
            np.sum([np.sum(x) for x in test_sentlabels]) / np.sum([len(x) for x in test_sentlabels]),
            np.mean([np.mean(x) for x in test_sentlabels])))
